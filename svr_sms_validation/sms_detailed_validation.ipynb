{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ce5a3f",
   "metadata": {},
   "source": [
    "# Comprehensive SMS-Aware SVR Validation Study\n",
    "\n",
    "This notebook performs detailed validation of SMS-aware Slice-to-Volume Reconstruction across multiple experimental conditions:\n",
    "\n",
    "- **Motion Levels:** none, mild, moderate, severe\n",
    "- **SMS Ratios (mb_factor):** 1, 2, 3, 4 (sequential to high multiband)\n",
    "- **Number of Stacks:** 3, 4, 5, 6, 7, 8\n",
    "\n",
    "The study evaluates:\n",
    "1. Transform averaging correctness (equality within SMS groups)\n",
    "2. Reconstruction quality vs ground truth (PSNR, SSIM, NRMSE)\n",
    "3. SMS vs sequential comparison at each motion level\n",
    "4. Statistical significance of results\n",
    "\n",
    "**Author:** Anand Joshi & AI Assistant  \n",
    "**Date:** November 2, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6ec1a9",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917cd4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263cd930",
   "metadata": {},
   "source": [
    "## 2. Define Experimental Parameters\n",
    "\n",
    "Set up the parameter space for comprehensive validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1da542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental parameters\n",
    "MOTION_LEVELS = {\n",
    "    'none': {'max_rot_deg': 0.0, 'max_trans_mm': 0.0, 'max_disp': 0.0},\n",
    "    'mild': {'max_rot_deg': 1.0, 'max_trans_mm': 0.5, 'max_disp': 2.0},\n",
    "    'moderate': {'max_rot_deg': 3.0, 'max_trans_mm': 1.0, 'max_disp': 5.0},\n",
    "    'severe': {'max_rot_deg': 5.0, 'max_trans_mm': 2.0, 'max_disp': 10.0}\n",
    "}\n",
    "\n",
    "MB_FACTORS = [1, 2, 3]  # SMS ratios to test\n",
    "NUM_STACKS_OPTIONS = [3, 6, 9, 12]  # Different stack counts\n",
    "\n",
    "# Fixed parameters\n",
    "GROUND_TRUTH_DIR = \"test_data/ground_truths\"  # Input folder with ground truth NIfTI files\n",
    "OUTPUT_DIR = \"test_data/sms_stacks_generated\"\n",
    "SLICES_PER_STACK = 20\n",
    "SLICE_THICKNESS = 3  # Slice thickness in mm (set to None to auto-calculate from n_stacks)\n",
    "INPLANE_RESOLUTION = 0.8  # In-plane resolution in mm\n",
    "\n",
    "# Find all ground truth NIfTI files\n",
    "ground_truth_files = sorted(Path(GROUND_TRUTH_DIR).glob(\"*.nii.gz\"))\n",
    "if not ground_truth_files:\n",
    "    ground_truth_files = sorted(Path(GROUND_TRUTH_DIR).glob(\"*.nii\"))\n",
    "\n",
    "if len(ground_truth_files) == 0:\n",
    "    raise ValueError(f\"No NIfTI files found in {GROUND_TRUTH_DIR}\")\n",
    "\n",
    "# Create output directory\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Stack Generation Configuration:\")\n",
    "print(f\"  Ground truth files: {len(ground_truth_files)}\")\n",
    "for i, gt_file in enumerate(ground_truth_files, 1):\n",
    "    print(f\"    {i}. {gt_file.name}\")\n",
    "print(f\"  Motion levels: {list(MOTION_LEVELS.keys())}\")\n",
    "print(f\"  MB factors: {MB_FACTORS}\")\n",
    "print(f\"  Stack counts: {NUM_STACKS_OPTIONS}\")\n",
    "print(f\"  Slice thickness: {SLICE_THICKNESS} mm\" if SLICE_THICKNESS else f\"  Slice thickness: Auto-calculated from stack count\")\n",
    "print(f\"  In-plane resolution: {INPLANE_RESOLUTION} mm\")\n",
    "print(f\"  Total stack sets per GT: {len(MOTION_LEVELS) * len(MB_FACTORS) * len(NUM_STACKS_OPTIONS)}\")\n",
    "print(f\"  Total stack sets: {len(ground_truth_files) * len(MOTION_LEVELS) * len(MB_FACTORS) * len(NUM_STACKS_OPTIONS)}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Time estimation\n",
    "total_stacks = len(ground_truth_files) * len(MOTION_LEVELS) * len(MB_FACTORS) * len(NUM_STACKS_OPTIONS)\n",
    "estimated_time_per_set_minutes = 5.0  # Estimated time to generate one stack set\n",
    "estimated_total_hours = (total_stacks * estimated_time_per_set_minutes) / 60\n",
    "print(f\"\\nTime Estimation:\")\n",
    "print(f\"  Estimated time per stack set: ~{estimated_time_per_set_minutes:.1f} minutes\")\n",
    "print(f\"  Estimated total time: ~{estimated_total_hours:.1f} hours ({estimated_total_hours*60:.0f} minutes)\")\n",
    "print(f\"  Per ground truth: ~{estimated_total_hours/len(ground_truth_files) if len(ground_truth_files) > 0 else 0:.1f} hours\")\n",
    "print(f\"  Note: Actual time depends on I/O speed and CPU performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f747f2a",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d43440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_stacks(ground_truth, output_dir, num_stacks, mb_factor, motion_params, timeout=600):\n",
    "    \"\"\"Simulate stacks with given parameters.\"\"\"\n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        \"simstack_scripts/simulate_stacks.py\",\n",
    "        ground_truth,\n",
    "        output_dir,\n",
    "        \"--n-stacks\", str(num_stacks),\n",
    "        \"--mb-factor\", str(mb_factor),\n",
    "        \"--max-rot-deg\", str(motion_params['max_rot_deg']),\n",
    "        \"--max-trans-mm\", str(motion_params['max_trans_mm']),\n",
    "        \"--max-disp\", str(motion_params['max_disp']),\n",
    "        \"--slice-thickness\", str(SLICE_THICKNESS),\n",
    "        \"--inplane-res\", str(INPLANE_RESOLUTION),\n",
    "        \"--noise-std\", \"0.02\",\n",
    "        \"--disable-nonlinear\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)\n",
    "        return result.returncode == 0, result.stdout, result.stderr\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return False, \"\", \"Simulation timeout\"\n",
    "\n",
    "print(\"Helper functions defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c93ca",
   "metadata": {},
   "source": [
    "## 4. Run Comprehensive Experiments\n",
    "\n",
    "Execute all combinations of parameters and collect results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57f004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tracking\n",
    "results = []\n",
    "stack_set_id = 0\n",
    "\n",
    "# Time tracking\n",
    "import time\n",
    "start_time = time.time()\n",
    "generation_times = []\n",
    "\n",
    "# Calculate total stack sets\n",
    "total_stack_sets = len(ground_truth_files) * len(MOTION_LEVELS) * len(MB_FACTORS) * len(NUM_STACKS_OPTIONS)\n",
    "\n",
    "print(f\"Starting stack generation...\")\n",
    "print(f\"Total stack sets to generate: {total_stack_sets}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Iterate through all ground truth files\n",
    "for gt_idx, ground_truth_path in enumerate(ground_truth_files, 1):\n",
    "    gt_name = ground_truth_path.stem  # filename without extension\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"GROUND TRUTH {gt_idx}/{len(ground_truth_files)}: {ground_truth_path.name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Verify ground truth exists and is readable\n",
    "    try:\n",
    "        gt_img = nib.load(str(ground_truth_path))\n",
    "        gt_shape = gt_img.shape\n",
    "        print(f\"  Loaded: shape={gt_shape}, dtype={gt_img.get_fdata().dtype}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR loading ground truth: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Iterate through all parameter combinations for this ground truth\n",
    "    for motion_level, mb_factor, num_stacks in product(MOTION_LEVELS.keys(), MB_FACTORS, NUM_STACKS_OPTIONS):\n",
    "        stack_set_id += 1\n",
    "        motion_params = MOTION_LEVELS[motion_level]\n",
    "        exp_start_time = time.time()\n",
    "        \n",
    "        # Calculate time estimates\n",
    "        if len(generation_times) > 0:\n",
    "            avg_time = np.mean(generation_times)\n",
    "            remaining_sets = total_stack_sets - stack_set_id + 1\n",
    "            eta_seconds = avg_time * remaining_sets\n",
    "            eta_hours = eta_seconds / 3600\n",
    "            eta_minutes = (eta_seconds % 3600) / 60\n",
    "            elapsed_hours = (time.time() - start_time) / 3600\n",
    "            \n",
    "            print(f\"\\n  Set {stack_set_id}/{total_stack_sets}: motion={motion_level}, mb={mb_factor}, n_stacks={num_stacks}\")\n",
    "            print(f\"    Progress: {stack_set_id/total_stack_sets*100:.1f}% | Elapsed: {elapsed_hours:.1f}h | ETA: {int(eta_hours)}h {int(eta_minutes)}m\")\n",
    "        else:\n",
    "            print(f\"\\n  Set {stack_set_id}/{total_stack_sets}: motion={motion_level}, mb={mb_factor}, n_stacks={num_stacks}\")\n",
    "            print(f\"    Progress: {stack_set_id/total_stack_sets*100:.1f}% | Warming up...\")\n",
    "        \n",
    "        # Create output directory for this stack set\n",
    "        output_subdir = Path(OUTPUT_DIR) / gt_name / f\"set_{stack_set_id:03d}_m{motion_level}_mb{mb_factor}_s{num_stacks}\"\n",
    "        \n",
    "        result = {\n",
    "            'set_id': stack_set_id,\n",
    "            'ground_truth': gt_name,\n",
    "            'gt_file': ground_truth_path.name,\n",
    "            'motion_level': motion_level,\n",
    "            'mb_factor': mb_factor,\n",
    "            'num_stacks': num_stacks,\n",
    "            'max_rot_deg': motion_params['max_rot_deg'],\n",
    "            'max_trans_mm': motion_params['max_trans_mm'],\n",
    "            'max_disp': motion_params['max_disp'],\n",
    "            'output_dir': str(output_subdir)\n",
    "        }\n",
    "        \n",
    "        # Generate stacks\n",
    "        print(\"    Generating stacks...\", end=\" \")\n",
    "        success, stdout, stderr = simulate_stacks(\n",
    "            str(ground_truth_path), str(output_subdir), num_stacks, mb_factor, motion_params\n",
    "        )\n",
    "        \n",
    "        if not success:\n",
    "            print(f\"FAILED\")\n",
    "            print(f\"    Error: {stderr[:200]}\")\n",
    "            result['status'] = 'failed'\n",
    "            result['error'] = stderr\n",
    "            results.append(result)\n",
    "            continue\n",
    "        \n",
    "        print(\"OK\")\n",
    "        \n",
    "        # Verify stacks were generated\n",
    "        stack_files = sorted(output_subdir.glob(\"sim_stack_*.nii.gz\"))\n",
    "        json_files = sorted(output_subdir.glob(\"sim_stack_*.json\"))\n",
    "        \n",
    "        if len(stack_files) == num_stacks and len(json_files) == num_stacks:\n",
    "            result['status'] = 'success'\n",
    "            result['num_generated'] = len(stack_files)\n",
    "            print(f\"    Generated {len(stack_files)} stacks with metadata\")\n",
    "        else:\n",
    "            result['status'] = 'incomplete'\n",
    "            result['num_generated'] = len(stack_files)\n",
    "            print(f\"    WARNING: Expected {num_stacks} stacks, got {len(stack_files)}\")\n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "        # Track generation time\n",
    "        gen_time = time.time() - exp_start_time\n",
    "        generation_times.append(gen_time)\n",
    "        print(f\"    Completed in {gen_time:.1f} seconds\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"STACK GENERATION COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "total_time = time.time() - start_time\n",
    "successful = sum(1 for r in results if r['status'] == 'success')\n",
    "print(f\"Total stack sets: {len(results)}\")\n",
    "print(f\"Successful: {successful}\")\n",
    "print(f\"Failed: {sum(1 for r in results if r['status'] == 'failed')}\")\n",
    "print(f\"Incomplete: {sum(1 for r in results if r['status'] == 'incomplete')}\")\n",
    "print(f\"Ground truths processed: {len(ground_truth_files)}\")\n",
    "print(f\"Total time: {total_time/3600:.2f} hours ({total_time/60:.1f} minutes)\")\n",
    "if len(generation_times) > 0:\n",
    "    print(f\"Average time per stack set: {np.mean(generation_times):.1f} seconds\")\n",
    "    print(f\"Total stacks generated: {successful * len(NUM_STACKS_OPTIONS) * len(MB_FACTORS) * len(MOTION_LEVELS)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ccd69",
   "metadata": {},
   "source": [
    "## 5. Create Results DataFrame and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2137a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"Total stack sets: {len(df)}\")\n",
    "print(f\"Successful: {(df['status'] == 'success').sum()}\")\n",
    "print(f\"Failed: {(df['status'] == 'failed').sum()}\")\n",
    "print(f\"Incomplete: {(df['status'] == 'incomplete').sum()}\")\n",
    "print(f\"\\nResults DataFrame shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Display statistics by ground truth\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATION STATISTICS BY GROUND TRUTH\")\n",
    "print(\"=\"*80)\n",
    "for gt_name in sorted(df['ground_truth'].unique()):\n",
    "    df_gt = df[df['ground_truth'] == gt_name]\n",
    "    successful_gt = (df_gt['status'] == 'success').sum()\n",
    "    print(f\"\\n{gt_name}:\")\n",
    "    print(f\"  Total sets: {len(df_gt)}\")\n",
    "    print(f\"  Successful: {successful_gt}\")\n",
    "    print(f\"  Success rate: {successful_gt/len(df_gt)*100:.1f}%\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE STACK SETS\")\n",
    "print(\"=\"*80)\n",
    "display(df[['set_id', 'ground_truth', 'motion_level', 'mb_factor', 'num_stacks', 'status']].head(20))\n",
    "\n",
    "# Save results\n",
    "results_file = Path(OUTPUT_DIR) / \"generation_results.csv\"\n",
    "df.to_csv(results_file, index=False)\n",
    "print(f\"\\nResults saved to: {results_file}\")\n",
    "\n",
    "# Summary by parameters\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUCCESS RATE BY PARAMETERS\")\n",
    "print(\"=\"*80)\n",
    "success_summary = df.groupby(['motion_level', 'mb_factor', 'num_stacks']).agg({\n",
    "    'status': lambda x: (x == 'success').sum(),\n",
    "    'set_id': 'count'\n",
    "}).rename(columns={'status': 'successful', 'set_id': 'total'})\n",
    "success_summary['rate'] = (success_summary['successful'] / success_summary['total'] * 100).round(1)\n",
    "print(success_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
