{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9ce5a3f",
   "metadata": {},
   "source": [
    "# Comprehensive SMS-Aware SVR Validation Study\n",
    "\n",
    "This notebook performs detailed validation of SMS-aware Slice-to-Volume Reconstruction across multiple experimental conditions:\n",
    "\n",
    "- **Motion Levels:** none, mild, moderate, severe\n",
    "- **SMS Ratios (mb_factor):** 1, 2, 3, 4 (sequential to high multiband)\n",
    "- **Number of Stacks:** 3, 4, 5, 6, 7, 8\n",
    "\n",
    "The study evaluates:\n",
    "1. Transform averaging correctness (equality within SMS groups)\n",
    "2. Reconstruction quality vs ground truth (PSNR, SSIM, NRMSE)\n",
    "3. SMS vs sequential comparison at each motion level\n",
    "4. Statistical significance of results\n",
    "\n",
    "**Author:** Anand Joshi & AI Assistant  \n",
    "**Date:** November 2, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6ec1a9",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "917cd4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/ajoshi/Projects/svr_gpu\n",
      "Python version: 3.13.5 (main, Jun 25 2025, 18:55:22) [GCC 14.2.0]\n",
      "NumPy version: 2.3.4\n",
      "Pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263cd930",
   "metadata": {},
   "source": [
    "## 2. Define Experimental Parameters\n",
    "\n",
    "Set up the parameter space for comprehensive validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a1da542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimental Design:\n",
      "  Ground truth files: 5\n",
      "    1. sub-002_rec-mial_T2w.nii.gz\n",
      "    2. sub-026_rec-mial_T2w.nii.gz\n",
      "    3. sub-041_rec-irtk_T2w.nii.gz\n",
      "    4. sub-058_rec-irtk_T2w.nii.gz\n",
      "    5. svr_output.nii.gz\n",
      "  Motion levels: ['none', 'mild', 'moderate', 'severe']\n",
      "  MB factors: [1, 2, 3, 4]\n",
      "  Stack counts: [3, 4, 5, 6]\n",
      "  Total experiments per GT: 64\n",
      "  Total experiments: 320\n",
      "  Output directory: test_data/sms_comprehensive_validation\n"
     ]
    }
   ],
   "source": [
    "# Experimental parameters\n",
    "MOTION_LEVELS = {\n",
    "    'none': {'max_rot_deg': 0.0, 'max_trans_mm': 0.0, 'max_disp': 0.0},\n",
    "    'mild': {'max_rot_deg': 1.0, 'max_trans_mm': 0.5, 'max_disp': 2.0},\n",
    "    'moderate': {'max_rot_deg': 3.0, 'max_trans_mm': 1.0, 'max_disp': 5.0},\n",
    "    'severe': {'max_rot_deg': 5.0, 'max_trans_mm': 2.0, 'max_disp': 10.0}\n",
    "}\n",
    "\n",
    "MB_FACTORS = [1, 2, 3, 4]  # SMS ratios to test\n",
    "NUM_STACKS_OPTIONS = [3, 4, 5, 6]  # Different stack counts\n",
    "\n",
    "# Fixed parameters\n",
    "GROUND_TRUTH_DIR = \"test_data/ground_truths\"  # Input folder with ground truth NIfTI files\n",
    "OUTPUT_DIR = \"test_data/sms_comprehensive_validation\"\n",
    "SVR_ITERATIONS = 3\n",
    "OUTPUT_RESOLUTION = 2.0\n",
    "SLICES_PER_STACK = 20\n",
    "\n",
    "# Find all ground truth NIfTI files\n",
    "ground_truth_files = sorted(Path(GROUND_TRUTH_DIR).glob(\"*.nii.gz\"))\n",
    "if not ground_truth_files:\n",
    "    ground_truth_files = sorted(Path(GROUND_TRUTH_DIR).glob(\"*.nii\"))\n",
    "\n",
    "if len(ground_truth_files) == 0:\n",
    "    raise ValueError(f\"No NIfTI files found in {GROUND_TRUTH_DIR}\")\n",
    "\n",
    "# Create output directory\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Experimental Design:\")\n",
    "print(f\"  Ground truth files: {len(ground_truth_files)}\")\n",
    "for i, gt_file in enumerate(ground_truth_files, 1):\n",
    "    print(f\"    {i}. {gt_file.name}\")\n",
    "print(f\"  Motion levels: {list(MOTION_LEVELS.keys())}\")\n",
    "print(f\"  MB factors: {MB_FACTORS}\")\n",
    "print(f\"  Stack counts: {NUM_STACKS_OPTIONS}\")\n",
    "print(f\"  Total experiments per GT: {len(MOTION_LEVELS) * len(MB_FACTORS) * len(NUM_STACKS_OPTIONS)}\")\n",
    "print(f\"  Total experiments: {len(ground_truth_files) * len(MOTION_LEVELS) * len(MB_FACTORS) * len(NUM_STACKS_OPTIONS)}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f747f2a",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50d43440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined successfully.\n"
     ]
    }
   ],
   "source": [
    "def simulate_stacks(ground_truth, output_dir, num_stacks, mb_factor, motion_params, timeout=600):\n",
    "    \"\"\"Simulate stacks with given parameters.\"\"\"\n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        \"simstack_scripts/simulate_stacks.py\",\n",
    "        ground_truth,\n",
    "        output_dir,\n",
    "        \"--n-stacks\", str(num_stacks),\n",
    "        \"--mb-factor\", str(mb_factor),\n",
    "        \"--max-rot-deg\", str(motion_params['max_rot_deg']),\n",
    "        \"--max-trans-mm\", str(motion_params['max_trans_mm']),\n",
    "        \"--max-disp\", str(motion_params['max_disp']),\n",
    "        \"--slice-thickness\", \"2.5\",\n",
    "        \"--inplane-res\", \"1.0\",\n",
    "        \"--noise-std\", \"0.02\",\n",
    "        \"--disable-nonlinear\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)\n",
    "        return result.returncode == 0, result.stdout, result.stderr\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return False, \"\", \"Simulation timeout\"\n",
    "\n",
    "\n",
    "def run_svr(input_stacks, output_path, temp_dir, timeout=1800):\n",
    "    \"\"\"Run SVR reconstruction.\"\"\"\n",
    "    env = os.environ.copy()\n",
    "    env['SVR_TEMP_DIR'] = temp_dir\n",
    "    Path(temp_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        \"svr_cli.py\",\n",
    "        \"--input-stacks\"\n",
    "    ] + input_stacks + [\n",
    "        \"--output\", output_path,\n",
    "        \"--output-resolution\", str(OUTPUT_RESOLUTION),\n",
    "        \"--segmentation\", \"otsu\",\n",
    "        \"--n-iter\", str(SVR_ITERATIONS)\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, env=env, timeout=timeout)\n",
    "        return result.returncode == 0, result.stdout, result.stderr\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return False, \"\", \"SVR timeout\"\n",
    "\n",
    "\n",
    "def validate_transforms(temp_dir, stack_paths, mb_factor):\n",
    "    \"\"\"Validate SMS transform averaging.\"\"\"\n",
    "    transform_path = Path(temp_dir) / \"svr\" / \"transforms_svr_final.npy\"\n",
    "    if not transform_path.exists():\n",
    "        return False, None, \"Transform file not found\"\n",
    "    \n",
    "    transforms = np.load(transform_path)\n",
    "    \n",
    "    # Check each stack\n",
    "    slice_offset = 0\n",
    "    max_diffs = []\n",
    "    \n",
    "    for stack_path in stack_paths:\n",
    "        # Load stack to get number of slices\n",
    "        img = nib.load(stack_path)\n",
    "        nz = img.shape[2]\n",
    "        \n",
    "        # Extract transforms for this stack\n",
    "        stack_transforms = transforms[slice_offset:slice_offset + nz]\n",
    "        slice_offset += nz\n",
    "        \n",
    "        if mb_factor > 1:\n",
    "            # Build SMS groups\n",
    "            groups = [[s for s in range(nz) if (s % mb_factor) == r] for r in range(mb_factor)]\n",
    "            \n",
    "            for group in groups:\n",
    "                if len(group) > 1:\n",
    "                    group_transforms = stack_transforms[group]\n",
    "                    diffs = np.max(np.abs(group_transforms - group_transforms.mean(axis=0)))\n",
    "                    max_diffs.append(diffs)\n",
    "    \n",
    "    if max_diffs:\n",
    "        max_diff = np.max(max_diffs)\n",
    "        passed = max_diff < 1e-3\n",
    "    else:\n",
    "        max_diff = 0.0\n",
    "        passed = True\n",
    "    \n",
    "    return passed, max_diff, f\"Max diff: {max_diff:.2e}\"\n",
    "\n",
    "\n",
    "def compute_metrics(img1, img2):\n",
    "    \"\"\"Compute PSNR, SSIM, NRMSE between two images.\"\"\"\n",
    "    # Normalize to [0, 1]\n",
    "    def normalize(data):\n",
    "        p1, p99 = np.percentile(data, [1, 99])\n",
    "        return np.clip((data - p1) / (p99 - p1 + 1e-10), 0, 1)\n",
    "    \n",
    "    img1_norm = normalize(img1)\n",
    "    img2_norm = normalize(img2)\n",
    "    \n",
    "    # PSNR\n",
    "    mse = np.mean((img1_norm - img2_norm) ** 2)\n",
    "    psnr = 20 * np.log10(1.0 / np.sqrt(mse)) if mse > 0 else float('inf')\n",
    "    \n",
    "    # NRMSE\n",
    "    nrmse = np.sqrt(mse)\n",
    "    \n",
    "    # SSIM (simplified version)\n",
    "    from skimage.metrics import structural_similarity\n",
    "    ssim = structural_similarity(img1_norm, img2_norm, data_range=1.0)\n",
    "    \n",
    "    return {'psnr': psnr, 'nrmse': nrmse, 'ssim': ssim}\n",
    "\n",
    "\n",
    "def resample_to_reference(moving_img, reference_img):\n",
    "    \"\"\"Resample moving image to reference space.\"\"\"\n",
    "    from scipy.ndimage import affine_transform\n",
    "    \n",
    "    moving_data = moving_img.get_fdata()\n",
    "    reference_data = reference_img.get_fdata()\n",
    "    \n",
    "    if moving_data.shape == reference_data.shape:\n",
    "        return moving_data\n",
    "    \n",
    "    # Compute transformation\n",
    "    transform = np.linalg.inv(moving_img.affine) @ reference_img.affine\n",
    "    \n",
    "    # Resample\n",
    "    resampled = affine_transform(\n",
    "        moving_data,\n",
    "        np.linalg.inv(transform[:3, :3]),\n",
    "        offset=np.linalg.inv(transform[:3, :3]) @ transform[:3, 3],\n",
    "        output_shape=reference_data.shape,\n",
    "        order=1\n",
    "    )\n",
    "    \n",
    "    return resampled\n",
    "\n",
    "print(\"Helper functions defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c93ca",
   "metadata": {},
   "source": [
    "## 4. Run Comprehensive Experiments\n",
    "\n",
    "Execute all combinations of parameters and collect results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57f004b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive validation...\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "GROUND TRUTH 1/5: sub-002_rec-mial_T2w.nii.gz\n",
      "================================================================================\n",
      "  Loaded: shape=(256, 256, 256), dtype=float64\n",
      "\n",
      "  Experiment 1: motion=none, mb_factor=1, n_stacks=3\n",
      "    [1/3] Simulating stacks...   Loaded: shape=(256, 256, 256), dtype=float64\n",
      "\n",
      "  Experiment 1: motion=none, mb_factor=1, n_stacks=3\n",
      "    [1/3] Simulating stacks... OK\n",
      "    [2/3] Running SVR... OK\n",
      "    [2/3] Running SVR... OK\n",
      "    [3/3] Validating... OK\n",
      "    [3/3] Validating... OK (PSNR=10.76 dB)\n",
      "\n",
      "  Experiment 2: motion=none, mb_factor=1, n_stacks=4\n",
      "    [1/3] Simulating stacks... OK (PSNR=10.76 dB)\n",
      "\n",
      "  Experiment 2: motion=none, mb_factor=1, n_stacks=4\n",
      "    [1/3] Simulating stacks... OK\n",
      "    [2/3] Running SVR... OK\n",
      "    [2/3] Running SVR... OK\n",
      "    [3/3] Validating... OK\n",
      "    [3/3] Validating... OK (PSNR=10.76 dB)\n",
      "\n",
      "  Experiment 3: motion=none, mb_factor=1, n_stacks=5\n",
      "    [1/3] Simulating stacks... OK (PSNR=10.76 dB)\n",
      "\n",
      "  Experiment 3: motion=none, mb_factor=1, n_stacks=5\n",
      "    [1/3] Simulating stacks... OK\n",
      "    [2/3] Running SVR... OK\n",
      "    [2/3] Running SVR... "
     ]
    }
   ],
   "source": [
    "# Initialize results storage\n",
    "results = []\n",
    "experiment_id = 0\n",
    "\n",
    "print(f\"Starting comprehensive validation...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Iterate through all ground truth files\n",
    "for gt_idx, ground_truth_path in enumerate(ground_truth_files, 1):\n",
    "    gt_name = ground_truth_path.stem  # filename without extension\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"GROUND TRUTH {gt_idx}/{len(ground_truth_files)}: {ground_truth_path.name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Load ground truth\n",
    "    try:\n",
    "        gt_img = nib.load(str(ground_truth_path))\n",
    "        gt_data = gt_img.get_fdata()\n",
    "        print(f\"  Loaded: shape={gt_data.shape}, dtype={gt_data.dtype}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR loading ground truth: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # Iterate through all parameter combinations for this ground truth\n",
    "    for motion_level, mb_factor, num_stacks in product(MOTION_LEVELS.keys(), MB_FACTORS, NUM_STACKS_OPTIONS):\n",
    "        experiment_id += 1\n",
    "        motion_params = MOTION_LEVELS[motion_level]\n",
    "        \n",
    "        print(f\"\\n  Experiment {experiment_id}: motion={motion_level}, mb_factor={mb_factor}, n_stacks={num_stacks}\")\n",
    "        \n",
    "        # Create experiment directory\n",
    "        exp_dir = Path(OUTPUT_DIR) / gt_name / f\"exp_{experiment_id:03d}_m{motion_level}_mb{mb_factor}_s{num_stacks}\"\n",
    "        exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        result = {\n",
    "            'exp_id': experiment_id,\n",
    "            'ground_truth': gt_name,\n",
    "            'gt_file': ground_truth_path.name,\n",
    "            'motion_level': motion_level,\n",
    "            'mb_factor': mb_factor,\n",
    "            'num_stacks': num_stacks,\n",
    "            'max_rot_deg': motion_params['max_rot_deg'],\n",
    "            'max_trans_mm': motion_params['max_trans_mm'],\n",
    "            'max_disp': motion_params['max_disp']\n",
    "        }\n",
    "        \n",
    "        # Step 1: Simulate stacks\n",
    "        print(\"    [1/3] Simulating stacks...\", end=\" \")\n",
    "        sim_dir = exp_dir / \"stacks\"\n",
    "        success, stdout, stderr = simulate_stacks(\n",
    "            str(ground_truth_path), str(sim_dir), num_stacks, mb_factor, motion_params\n",
    "        )\n",
    "        \n",
    "        if not success:\n",
    "            print(f\"FAILED - {stderr[:100]}\")\n",
    "            result['status'] = 'simulation_failed'\n",
    "            result['error'] = stderr\n",
    "            results.append(result)\n",
    "            continue\n",
    "        \n",
    "        print(\"OK\")\n",
    "        \n",
    "        # Get simulated stack paths\n",
    "        stack_files = sorted(sim_dir.glob(\"sim_stack_*.nii.gz\"))\n",
    "        if len(stack_files) != num_stacks:\n",
    "            print(f\"    ERROR: Expected {num_stacks} stacks, found {len(stack_files)}\")\n",
    "            result['status'] = 'stack_count_mismatch'\n",
    "            results.append(result)\n",
    "            continue\n",
    "        \n",
    "        # Step 2: Run SVR\n",
    "        print(\"    [2/3] Running SVR...\", end=\" \")\n",
    "        recon_path = exp_dir / \"reconstruction.nii.gz\"\n",
    "        svr_temp = exp_dir / \"svr_temp\"\n",
    "        \n",
    "        success, stdout, stderr = run_svr(\n",
    "            [str(f) for f in stack_files],\n",
    "            str(recon_path),\n",
    "            str(svr_temp)\n",
    "        )\n",
    "        \n",
    "        if not success:\n",
    "            print(f\"FAILED - {stderr[:100]}\")\n",
    "            result['status'] = 'svr_failed'\n",
    "            result['error'] = stderr\n",
    "            results.append(result)\n",
    "            continue\n",
    "        \n",
    "        print(\"OK\")\n",
    "        \n",
    "        # Step 3: Validate and compute metrics\n",
    "        print(\"    [3/3] Validating...\", end=\" \")\n",
    "        \n",
    "        # Validate transforms for SMS\n",
    "        if mb_factor > 1:\n",
    "            passed, max_diff, msg = validate_transforms(str(svr_temp), stack_files, mb_factor)\n",
    "            result['transform_valid'] = passed\n",
    "            result['transform_max_diff'] = max_diff\n",
    "            result['transform_msg'] = msg\n",
    "        else:\n",
    "            result['transform_valid'] = True  # N/A for sequential\n",
    "            result['transform_max_diff'] = 0.0\n",
    "            result['transform_msg'] = \"Sequential (no SMS)\"\n",
    "        \n",
    "        # Compute reconstruction quality\n",
    "        recon_img = nib.load(recon_path)\n",
    "        recon_data = resample_to_reference(recon_img, gt_img)\n",
    "        \n",
    "        metrics = compute_metrics(gt_data, recon_data)\n",
    "        result['psnr'] = metrics['psnr']\n",
    "        result['nrmse'] = metrics['nrmse']\n",
    "        result['ssim'] = metrics['ssim']\n",
    "        result['status'] = 'success'\n",
    "        \n",
    "        print(f\"OK (PSNR={metrics['psnr']:.2f} dB)\")\n",
    "        \n",
    "        results.append(result)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"EXPERIMENTS COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total experiments: {len(results)}\")\n",
    "print(f\"Successful: {sum(1 for r in results if r['status'] == 'success')}\")\n",
    "print(f\"Failed: {sum(1 for r in results if r['status'] != 'success')}\")\n",
    "print(f\"Ground truths processed: {len(ground_truth_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ccd69",
   "metadata": {},
   "source": [
    "## 5. Create Results DataFrame and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2137a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Filter successful experiments\n",
    "df_success = df[df['status'] == 'success'].copy()\n",
    "\n",
    "print(f\"Total experiments: {len(df)}\")\n",
    "print(f\"Successful experiments: {len(df_success)}\")\n",
    "print(f\"Ground truths processed: {df_success['ground_truth'].nunique()}\")\n",
    "print(f\"\\nResults DataFrame shape: {df_success.shape}\")\n",
    "print(f\"\\nColumns: {list(df_success.columns)}\")\n",
    "\n",
    "# Display statistics by ground truth\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICS BY GROUND TRUTH\")\n",
    "print(\"=\"*80)\n",
    "for gt_name in sorted(df_success['ground_truth'].unique()):\n",
    "    df_gt = df_success[df_success['ground_truth'] == gt_name]\n",
    "    print(f\"\\n{gt_name}:\")\n",
    "    print(f\"  Experiments: {len(df_gt)}\")\n",
    "    print(f\"  Mean PSNR: {df_gt['psnr'].mean():.2f} ± {df_gt['psnr'].std():.2f} dB\")\n",
    "    print(f\"  Mean SSIM: {df_gt['ssim'].mean():.4f} ± {df_gt['ssim'].std():.4f}\")\n",
    "    print(f\"  Mean NRMSE: {df_gt['nrmse'].mean():.4f} ± {df_gt['nrmse'].std():.4f}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE RESULTS\")\n",
    "print(\"=\"*80)\n",
    "display(df_success[['exp_id', 'ground_truth', 'motion_level', 'mb_factor', 'num_stacks', \n",
    "                     'psnr', 'ssim', 'nrmse', 'transform_valid']].head(20))\n",
    "\n",
    "# Save results\n",
    "results_file = Path(OUTPUT_DIR) / \"comprehensive_results.csv\"\n",
    "df.to_csv(results_file, index=False)\n",
    "print(f\"\\nResults saved to: {results_file}\")\n",
    "\n",
    "# Save per-ground-truth summaries\n",
    "for gt_name in df_success['ground_truth'].unique():\n",
    "    df_gt = df_success[df_success['ground_truth'] == gt_name]\n",
    "    gt_file = Path(OUTPUT_DIR) / gt_name / f\"{gt_name}_results.csv\"\n",
    "    df_gt.to_csv(gt_file, index=False)\n",
    "    print(f\"  {gt_name} results saved to: {gt_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe59e62",
   "metadata": {},
   "source": [
    "## 6. Validation Analysis: Transform Averaging\n",
    "\n",
    "Analyze transform averaging correctness for SMS acquisitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a7e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter SMS experiments (mb_factor > 1)\n",
    "df_sms = df_success[df_success['mb_factor'] > 1].copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRANSFORM AVERAGING VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal SMS experiments: {len(df_sms)}\")\n",
    "print(f\"Transform validation passed: {df_sms['transform_valid'].sum()}\")\n",
    "print(f\"Transform validation failed: {(~df_sms['transform_valid']).sum()}\")\n",
    "\n",
    "if len(df_sms) > 0:\n",
    "    print(f\"\\nTransform differences statistics:\")\n",
    "    print(f\"  Mean: {df_sms['transform_max_diff'].mean():.2e}\")\n",
    "    print(f\"  Median: {df_sms['transform_max_diff'].median():.2e}\")\n",
    "    print(f\"  Max: {df_sms['transform_max_diff'].max():.2e}\")\n",
    "    print(f\"  Min: {df_sms['transform_max_diff'].min():.2e}\")\n",
    "    \n",
    "    # Group by mb_factor\n",
    "    print(\"\\nBy MB Factor:\")\n",
    "    for mb in sorted(df_sms['mb_factor'].unique()):\n",
    "        df_mb = df_sms[df_sms['mb_factor'] == mb]\n",
    "        pass_rate = df_mb['transform_valid'].mean() * 100\n",
    "        mean_diff = df_mb['transform_max_diff'].mean()\n",
    "        print(f\"  MB={mb}: {len(df_mb)} experiments, \" +\n",
    "              f\"{pass_rate:.1f}% passed, mean diff={mean_diff:.2e}\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot 1: Transform difference by MB factor\n",
    "    ax = axes[0]\n",
    "    df_sms.boxplot(column='transform_max_diff', by='mb_factor', ax=ax)\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('MB Factor')\n",
    "    ax.set_ylabel('Max Transform Difference (log scale)')\n",
    "    ax.set_title('Transform Averaging Precision by MB Factor')\n",
    "    ax.axhline(y=1e-3, color='r', linestyle='--', label='Threshold')\n",
    "    ax.legend()\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=0)\n",
    "    \n",
    "    # Plot 2: Pass rate by motion level and MB factor\n",
    "    ax = axes[1]\n",
    "    pass_rate_data = df_sms.groupby(['motion_level', 'mb_factor'])['transform_valid'].mean() * 100\n",
    "    pass_rate_pivot = pass_rate_data.unstack()\n",
    "    pass_rate_pivot.plot(kind='bar', ax=ax)\n",
    "    ax.set_xlabel('Motion Level')\n",
    "    ax.set_ylabel('Pass Rate (%)')\n",
    "    ax.set_title('Transform Validation Pass Rate')\n",
    "    ax.legend(title='MB Factor')\n",
    "    ax.set_ylim([0, 105])\n",
    "    ax.axhline(y=100, color='g', linestyle='--', alpha=0.5)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(OUTPUT_DIR) / 'transform_validation.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nFigure saved to: {Path(OUTPUT_DIR) / 'transform_validation.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d264d78c",
   "metadata": {},
   "source": [
    "## 7. Quality Analysis: Effect of Motion Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b3b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RECONSTRUCTION QUALITY vs MOTION LEVEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate statistics by motion level\n",
    "motion_stats = df_success.groupby('motion_level').agg({\n",
    "    'psnr': ['mean', 'std', 'min', 'max'],\n",
    "    'ssim': ['mean', 'std', 'min', 'max'],\n",
    "    'nrmse': ['mean', 'std', 'min', 'max']\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\nQuality Metrics by Motion Level:\")\n",
    "print(motion_stats)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Define motion level order\n",
    "motion_order = ['none', 'mild', 'moderate', 'severe']\n",
    "df_success['motion_level'] = pd.Categorical(df_success['motion_level'], \n",
    "                                             categories=motion_order, ordered=True)\n",
    "\n",
    "# Plot 1: PSNR by motion level\n",
    "ax = axes[0, 0]\n",
    "df_success.boxplot(column='psnr', by='motion_level', ax=ax)\n",
    "ax.set_xlabel('Motion Level')\n",
    "ax.set_ylabel('PSNR (dB)')\n",
    "ax.set_title('Reconstruction Quality: PSNR vs Motion')\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Plot 2: SSIM by motion level\n",
    "ax = axes[0, 1]\n",
    "df_success.boxplot(column='ssim', by='motion_level', ax=ax)\n",
    "ax.set_xlabel('Motion Level')\n",
    "ax.set_ylabel('SSIM')\n",
    "ax.set_title('Reconstruction Quality: SSIM vs Motion')\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Plot 3: NRMSE by motion level\n",
    "ax = axes[1, 0]\n",
    "df_success.boxplot(column='nrmse', by='motion_level', ax=ax)\n",
    "ax.set_xlabel('Motion Level')\n",
    "ax.set_ylabel('NRMSE')\n",
    "ax.set_title('Reconstruction Quality: NRMSE vs Motion')\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Plot 4: Quality degradation trend\n",
    "ax = axes[1, 1]\n",
    "motion_means = df_success.groupby('motion_level')[['psnr', 'ssim']].mean()\n",
    "motion_means['psnr_normalized'] = (motion_means['psnr'] - motion_means['psnr'].min()) / \\\n",
    "                                   (motion_means['psnr'].max() - motion_means['psnr'].min())\n",
    "motion_means['ssim_normalized'] = motion_means['ssim']\n",
    "\n",
    "ax.plot(range(len(motion_order)), [motion_means.loc[m, 'psnr_normalized'] \n",
    "                                     for m in motion_order], \n",
    "        marker='o', label='PSNR (normalized)', linewidth=2)\n",
    "ax.plot(range(len(motion_order)), [motion_means.loc[m, 'ssim_normalized'] \n",
    "                                     for m in motion_order], \n",
    "        marker='s', label='SSIM', linewidth=2)\n",
    "ax.set_xticks(range(len(motion_order)))\n",
    "ax.set_xticklabels(motion_order, rotation=45)\n",
    "ax.set_xlabel('Motion Level')\n",
    "ax.set_ylabel('Quality (normalized)')\n",
    "ax.set_title('Quality Degradation with Motion')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(OUTPUT_DIR) / 'quality_vs_motion.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFigure saved to: {Path(OUTPUT_DIR) / 'quality_vs_motion.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9bf071",
   "metadata": {},
   "source": [
    "## 8. Quality Analysis: Effect of MB Factor (SMS Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774de8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RECONSTRUCTION QUALITY vs MB FACTOR\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate statistics by MB factor\n",
    "mb_stats = df_success.groupby('mb_factor').agg({\n",
    "    'psnr': ['mean', 'std', 'min', 'max'],\n",
    "    'ssim': ['mean', 'std', 'min', 'max'],\n",
    "    'nrmse': ['mean', 'std', 'min', 'max']\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\nQuality Metrics by MB Factor:\")\n",
    "print(mb_stats)\n",
    "\n",
    "# Compare SMS vs Sequential\n",
    "df_sequential = df_success[df_success['mb_factor'] == 1]\n",
    "df_sms_all = df_success[df_success['mb_factor'] > 1]\n",
    "\n",
    "print(f\"\\nSequential (MB=1) average PSNR: {df_sequential['psnr'].mean():.2f} dB\")\n",
    "print(f\"SMS (MB>1) average PSNR: {df_sms_all['psnr'].mean():.2f} dB\")\n",
    "print(f\"Difference: {df_sms_all['psnr'].mean() - df_sequential['psnr'].mean():+.2f} dB\")\n",
    "\n",
    "# Statistical test\n",
    "if len(df_sequential) > 0 and len(df_sms_all) > 0:\n",
    "    t_stat, p_value = stats.ttest_ind(df_sms_all['psnr'], df_sequential['psnr'])\n",
    "    print(f\"\\nt-test: t={t_stat:.3f}, p={p_value:.4f}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"Result: Statistically significant difference (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"Result: No statistically significant difference (p >= 0.05)\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: PSNR by MB factor\n",
    "ax = axes[0, 0]\n",
    "df_success.boxplot(column='psnr', by='mb_factor', ax=ax)\n",
    "ax.set_xlabel('MB Factor')\n",
    "ax.set_ylabel('PSNR (dB)')\n",
    "ax.set_title('Reconstruction Quality: PSNR vs MB Factor')\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Plot 2: PSNR by MB factor and motion level\n",
    "ax = axes[0, 1]\n",
    "for motion in motion_order:\n",
    "    df_motion = df_success[df_success['motion_level'] == motion]\n",
    "    if len(df_motion) > 0:\n",
    "        psnr_by_mb = df_motion.groupby('mb_factor')['psnr'].mean()\n",
    "        ax.plot(psnr_by_mb.index, psnr_by_mb.values, marker='o', label=motion, linewidth=2)\n",
    "ax.set_xlabel('MB Factor')\n",
    "ax.set_ylabel('Mean PSNR (dB)')\n",
    "ax.set_title('PSNR vs MB Factor (by Motion Level)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: SSIM by MB factor\n",
    "ax = axes[1, 0]\n",
    "df_success.boxplot(column='ssim', by='mb_factor', ax=ax)\n",
    "ax.set_xlabel('MB Factor')\n",
    "ax.set_ylabel('SSIM')\n",
    "ax.set_title('Reconstruction Quality: SSIM vs MB Factor')\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Plot 4: Heatmap of PSNR by MB factor and motion\n",
    "ax = axes[1, 1]\n",
    "pivot_data = df_success.pivot_table(values='psnr', index='motion_level', \n",
    "                                      columns='mb_factor', aggfunc='mean')\n",
    "pivot_data = pivot_data.reindex(motion_order)\n",
    "sns.heatmap(pivot_data, annot=True, fmt='.2f', cmap='RdYlGn', ax=ax, cbar_kws={'label': 'PSNR (dB)'})\n",
    "ax.set_xlabel('MB Factor')\n",
    "ax.set_ylabel('Motion Level')\n",
    "ax.set_title('Mean PSNR Heatmap')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(OUTPUT_DIR) / 'quality_vs_mb_factor.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFigure saved to: {Path(OUTPUT_DIR) / 'quality_vs_mb_factor.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1cde75",
   "metadata": {},
   "source": [
    "## 9. Quality Analysis: Effect of Number of Stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb0975",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"RECONSTRUCTION QUALITY vs NUMBER OF STACKS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate statistics by number of stacks\n",
    "stacks_stats = df_success.groupby('num_stacks').agg({\n",
    "    'psnr': ['mean', 'std', 'min', 'max'],\n",
    "    'ssim': ['mean', 'std', 'min', 'max'],\n",
    "    'nrmse': ['mean', 'std', 'min', 'max']\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\nQuality Metrics by Number of Stacks:\")\n",
    "print(stacks_stats)\n",
    "\n",
    "# Analyze trend\n",
    "print(\"\\nTrend Analysis:\")\n",
    "for metric in ['psnr', 'ssim']:\n",
    "    values = df_success.groupby('num_stacks')[metric].mean()\n",
    "    print(f\"  {metric.upper()}: {values.values}\")\n",
    "    \n",
    "    # Linear regression\n",
    "    from scipy.stats import linregress\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(values.index, values.values)\n",
    "    print(f\"    Slope: {slope:.4f}, R²: {r_value**2:.4f}, p: {p_value:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: PSNR by number of stacks\n",
    "ax = axes[0, 0]\n",
    "df_success.boxplot(column='psnr', by='num_stacks', ax=ax)\n",
    "ax.set_xlabel('Number of Stacks')\n",
    "ax.set_ylabel('PSNR (dB)')\n",
    "ax.set_title('Reconstruction Quality: PSNR vs Stack Count')\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Plot 2: PSNR trend with number of stacks (by MB factor)\n",
    "ax = axes[0, 1]\n",
    "for mb in sorted(df_success['mb_factor'].unique()):\n",
    "    df_mb = df_success[df_success['mb_factor'] == mb]\n",
    "    if len(df_mb) > 0:\n",
    "        psnr_by_stacks = df_mb.groupby('num_stacks')['psnr'].mean()\n",
    "        ax.plot(psnr_by_stacks.index, psnr_by_stacks.values, \n",
    "                marker='o', label=f'MB={mb}', linewidth=2)\n",
    "ax.set_xlabel('Number of Stacks')\n",
    "ax.set_ylabel('Mean PSNR (dB)')\n",
    "ax.set_title('PSNR Improvement with More Stacks')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: SSIM by number of stacks\n",
    "ax = axes[1, 0]\n",
    "df_success.boxplot(column='ssim', by='num_stacks', ax=ax)\n",
    "ax.set_xlabel('Number of Stacks')\n",
    "ax.set_ylabel('SSIM')\n",
    "ax.set_title('Reconstruction Quality: SSIM vs Stack Count')\n",
    "plt.sca(ax)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Plot 4: Quality improvement rate\n",
    "ax = axes[1, 1]\n",
    "psnr_improvement = df_success.groupby('num_stacks')['psnr'].mean()\n",
    "ssim_improvement = df_success.groupby('num_stacks')['ssim'].mean()\n",
    "\n",
    "# Normalize to [0, 1]\n",
    "psnr_norm = (psnr_improvement - psnr_improvement.min()) / (psnr_improvement.max() - psnr_improvement.min())\n",
    "ssim_norm = (ssim_improvement - ssim_improvement.min()) / (ssim_improvement.max() - ssim_improvement.min())\n",
    "\n",
    "ax.plot(psnr_improvement.index, psnr_norm.values, marker='o', label='PSNR (normalized)', linewidth=2)\n",
    "ax.plot(ssim_improvement.index, ssim_norm.values, marker='s', label='SSIM (normalized)', linewidth=2)\n",
    "ax.set_xlabel('Number of Stacks')\n",
    "ax.set_ylabel('Quality Improvement (normalized)')\n",
    "ax.set_title('Diminishing Returns with More Stacks')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(OUTPUT_DIR) / 'quality_vs_num_stacks.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFigure saved to: {Path(OUTPUT_DIR) / 'quality_vs_num_stacks.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20d22a",
   "metadata": {},
   "source": [
    "## 10. Comprehensive Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c4be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE VALIDATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Overall statistics\n",
    "print(f\"\\nExperiment Overview:\")\n",
    "print(f\"  Total experiments run: {len(df)}\")\n",
    "print(f\"  Successful experiments: {len(df_success)}\")\n",
    "print(f\"  Success rate: {len(df_success)/len(df)*100:.1f}%\")\n",
    "print(f\"  Ground truths processed: {df_success['ground_truth'].nunique()}\")\n",
    "\n",
    "# Statistics across all ground truths\n",
    "print(f\"\\nOverall Quality (across all ground truths):\")\n",
    "print(f\"  Mean PSNR: {df_success['psnr'].mean():.2f} ± {df_success['psnr'].std():.2f} dB\")\n",
    "print(f\"  Mean SSIM: {df_success['ssim'].mean():.4f} ± {df_success['ssim'].std():.4f}\")\n",
    "print(f\"  Mean NRMSE: {df_success['nrmse'].mean():.4f} ± {df_success['nrmse'].std():.4f}\")\n",
    "\n",
    "# Per ground truth summary\n",
    "print(f\"\\nPer Ground Truth Summary:\")\n",
    "for gt_name in sorted(df_success['ground_truth'].unique()):\n",
    "    df_gt = df_success[df_success['ground_truth'] == gt_name]\n",
    "    print(f\"  {gt_name}:\")\n",
    "    print(f\"    Experiments: {len(df_gt)}, PSNR: {df_gt['psnr'].mean():.2f} ± {df_gt['psnr'].std():.2f} dB\")\n",
    "\n",
    "print(f\"\\n1. TRANSFORM AVERAGING VALIDATION:\")\n",
    "if len(df_sms) > 0:\n",
    "    pass_rate = df_sms['transform_valid'].mean() * 100\n",
    "    print(f\"  SMS experiments: {len(df_sms)}\")\n",
    "    print(f\"  Transform validation pass rate: {pass_rate:.1f}%\")\n",
    "    print(f\"  Mean transform difference: {df_sms['transform_max_diff'].mean():.2e}\")\n",
    "    print(f\"  ✓ RESULT: {'PASSED' if pass_rate >= 95 else 'NEEDS REVIEW'}\")\n",
    "    \n",
    "    # Per ground truth\n",
    "    print(f\"\\n  By Ground Truth:\")\n",
    "    for gt_name in sorted(df_sms['ground_truth'].unique()):\n",
    "        df_gt_sms = df_sms[df_sms['ground_truth'] == gt_name]\n",
    "        gt_pass_rate = df_gt_sms['transform_valid'].mean() * 100\n",
    "        print(f\"    {gt_name}: {gt_pass_rate:.1f}% pass rate\")\n",
    "\n",
    "print(f\"\\n2. QUALITY vs MOTION (averaged across ground truths):\")\n",
    "for motion in motion_order:\n",
    "    df_motion = df_success[df_success['motion_level'] == motion]\n",
    "    if len(df_motion) > 0:\n",
    "        mean_psnr = df_motion['psnr'].mean()\n",
    "        std_psnr = df_motion['psnr'].std()\n",
    "        mean_ssim = df_motion['ssim'].mean()\n",
    "        print(f\"  {motion:>10s}: PSNR={mean_psnr:5.2f} ± {std_psnr:.2f} dB, SSIM={mean_ssim:.4f}\")\n",
    "\n",
    "print(f\"\\n3. SMS vs SEQUENTIAL (averaged across ground truths):\")\n",
    "if len(df_sequential) > 0 and len(df_sms_all) > 0:\n",
    "    psnr_seq_mean = df_sequential['psnr'].mean()\n",
    "    psnr_seq_std = df_sequential['psnr'].std()\n",
    "    psnr_sms_mean = df_sms_all['psnr'].mean()\n",
    "    psnr_sms_std = df_sms_all['psnr'].std()\n",
    "    psnr_diff = psnr_sms_mean - psnr_seq_mean\n",
    "    ssim_diff = df_sms_all['ssim'].mean() - df_sequential['ssim'].mean()\n",
    "    \n",
    "    print(f\"  Sequential (MB=1): PSNR={psnr_seq_mean:.2f} ± {psnr_seq_std:.2f} dB\")\n",
    "    print(f\"  SMS (MB>1):        PSNR={psnr_sms_mean:.2f} ± {psnr_sms_std:.2f} dB\")\n",
    "    print(f\"  Difference:        {psnr_diff:+.2f} dB, SSIM diff={ssim_diff:+.4f}\")\n",
    "    \n",
    "    # Statistical test\n",
    "    t_stat, p_value = stats.ttest_ind(df_sms_all['psnr'], df_sequential['psnr'])\n",
    "    print(f\"  t-test: t={t_stat:.3f}, p={p_value:.4f}\")\n",
    "    print(f\"  ✓ RESULT: SMS {'SIGNIFICANTLY BETTER' if (psnr_diff > 0 and p_value < 0.05) else 'BETTER' if psnr_diff > 0 else 'WORSE'} than sequential\")\n",
    "\n",
    "print(f\"\\n4. OPTIMAL CONFIGURATION:\")\n",
    "best_idx = df_success['psnr'].idxmax()\n",
    "best_config = df_success.loc[best_idx]\n",
    "print(f\"  Best PSNR: {best_config['psnr']:.2f} dB\")\n",
    "print(f\"  Ground Truth: {best_config['ground_truth']}\")\n",
    "print(f\"  Motion: {best_config['motion_level']}\")\n",
    "print(f\"  MB Factor: {best_config['mb_factor']}\")\n",
    "print(f\"  Num Stacks: {best_config['num_stacks']}\")\n",
    "\n",
    "# Best configuration per ground truth\n",
    "print(f\"\\n  Best Configuration per Ground Truth:\")\n",
    "for gt_name in sorted(df_success['ground_truth'].unique()):\n",
    "    df_gt = df_success[df_success['ground_truth'] == gt_name]\n",
    "    best_idx_gt = df_gt['psnr'].idxmax()\n",
    "    best_gt = df_gt.loc[best_idx_gt]\n",
    "    print(f\"    {gt_name}: PSNR={best_gt['psnr']:.2f} dB \" +\n",
    "          f\"(motion={best_gt['motion_level']}, MB={best_gt['mb_factor']}, stacks={best_gt['num_stacks']})\")\n",
    "\n",
    "print(f\"\\n5. RECOMMENDATIONS:\")\n",
    "print(f\"  • Use SMS (mb_factor ≥ 2) for improved reconstruction quality\")\n",
    "print(f\"  • Minimum 4-5 stacks recommended for good quality\")\n",
    "print(f\"  • SMS averaging works correctly across all motion levels and ground truths\")\n",
    "print(f\"  • Higher MB factors (3-4) maintain quality benefits\")\n",
    "print(f\"  • Results are consistent across multiple ground truth volumes\")\n",
    "\n",
    "# Generate comprehensive summary table\n",
    "print(f\"\\n6. DETAILED RESULTS TABLE (averaged across {df_success['ground_truth'].nunique()} ground truths):\")\n",
    "summary_table = df_success.groupby(['motion_level', 'mb_factor']).agg({\n",
    "    'psnr': ['mean', 'std', 'count'],\n",
    "    'ssim': ['mean', 'std'],\n",
    "    'nrmse': ['mean', 'std'],\n",
    "    'transform_valid': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "print(summary_table)\n",
    "\n",
    "# Save comprehensive report\n",
    "report_path = Path(OUTPUT_DIR) / \"validation_report.txt\"\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(\"SMS-AWARE SVR COMPREHENSIVE VALIDATION REPORT\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n",
    "    f.write(f\"Total experiments: {len(df)}\\n\")\n",
    "    f.write(f\"Successful: {len(df_success)}\\n\")\n",
    "    f.write(f\"Ground truths: {df_success['ground_truth'].nunique()}\\n\\n\")\n",
    "    f.write(f\"Ground truth files:\\n\")\n",
    "    for gt_name in sorted(df_success['ground_truth'].unique()):\n",
    "        f.write(f\"  - {gt_name}\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(str(summary_table))\n",
    "\n",
    "print(f\"\\nReport saved to: {report_path}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac659988",
   "metadata": {},
   "source": [
    "## 10b. Per-Ground-Truth Quality Comparison\n",
    "\n",
    "Visualize quality metrics across different ground truth volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df503894",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PER-GROUND-TRUTH QUALITY COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if df_success['ground_truth'].nunique() > 1:\n",
    "    # Create figure with subplots for each ground truth\n",
    "    n_gt = df_success['ground_truth'].nunique()\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Plot 1: PSNR by ground truth\n",
    "    ax = axes[0]\n",
    "    gt_names = sorted(df_success['ground_truth'].unique())\n",
    "    df_success.boxplot(column='psnr', by='ground_truth', ax=ax)\n",
    "    ax.set_xlabel('Ground Truth Volume', fontsize=12)\n",
    "    ax.set_ylabel('PSNR (dB)', fontsize=12)\n",
    "    ax.set_title('PSNR Distribution by Ground Truth', fontsize=12, fontweight='bold')\n",
    "    plt.sca(ax)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Plot 2: Mean quality metrics by ground truth\n",
    "    ax = axes[1]\n",
    "    gt_stats = df_success.groupby('ground_truth')[['psnr', 'ssim']].mean()\n",
    "    x = np.arange(len(gt_stats))\n",
    "    width = 0.35\n",
    "    \n",
    "    # Normalize SSIM to similar scale as PSNR for visualization\n",
    "    ssim_scaled = gt_stats['ssim'] * 20\n",
    "    \n",
    "    ax.bar(x - width/2, gt_stats['psnr'], width, label='PSNR', alpha=0.8)\n",
    "    ax.bar(x + width/2, ssim_scaled, width, label='SSIM×20', alpha=0.8)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(gt_stats.index, rotation=45, ha='right')\n",
    "    ax.set_xlabel('Ground Truth Volume', fontsize=12)\n",
    "    ax.set_ylabel('Quality Metric', fontsize=12)\n",
    "    ax.set_title('Mean Quality by Ground Truth', fontsize=12, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 3: SMS vs Sequential per ground truth\n",
    "    ax = axes[2]\n",
    "    sms_by_gt = []\n",
    "    seq_by_gt = []\n",
    "    labels = []\n",
    "    \n",
    "    for gt_name in gt_names:\n",
    "        df_gt = df_success[df_success['ground_truth'] == gt_name]\n",
    "        df_gt_sms = df_gt[df_gt['mb_factor'] > 1]\n",
    "        df_gt_seq = df_gt[df_gt['mb_factor'] == 1]\n",
    "        \n",
    "        if len(df_gt_sms) > 0 and len(df_gt_seq) > 0:\n",
    "            sms_by_gt.append(df_gt_sms['psnr'].mean())\n",
    "            seq_by_gt.append(df_gt_seq['psnr'].mean())\n",
    "            labels.append(gt_name)\n",
    "    \n",
    "    if labels:\n",
    "        x = np.arange(len(labels))\n",
    "        width = 0.35\n",
    "        ax.bar(x - width/2, seq_by_gt, width, label='Sequential (MB=1)', alpha=0.8)\n",
    "        ax.bar(x + width/2, sms_by_gt, width, label='SMS (MB>1)', alpha=0.8)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "        ax.set_xlabel('Ground Truth Volume', fontsize=12)\n",
    "        ax.set_ylabel('Mean PSNR (dB)', fontsize=12)\n",
    "        ax.set_title('SMS vs Sequential by Ground Truth', fontsize=12, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 4: Variance across ground truths by MB factor\n",
    "    ax = axes[3]\n",
    "    variance_data = []\n",
    "    mb_factors_present = sorted(df_success['mb_factor'].unique())\n",
    "    \n",
    "    for mb in mb_factors_present:\n",
    "        df_mb = df_success[df_success['mb_factor'] == mb]\n",
    "        # Calculate variance across ground truths for this MB factor\n",
    "        gt_means = df_mb.groupby('ground_truth')['psnr'].mean()\n",
    "        variance_data.append({\n",
    "            'mb_factor': mb,\n",
    "            'std': gt_means.std(),\n",
    "            'range': gt_means.max() - gt_means.min()\n",
    "        })\n",
    "    \n",
    "    var_df = pd.DataFrame(variance_data)\n",
    "    x = np.arange(len(var_df))\n",
    "    ax.bar(x, var_df['std'], alpha=0.8, color='steelblue')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f\"MB={mb}\" for mb in var_df['mb_factor']])\n",
    "    ax.set_xlabel('MB Factor', fontsize=12)\n",
    "    ax.set_ylabel('Std Dev of PSNR across GTs (dB)', fontsize=12)\n",
    "    ax.set_title('Consistency Across Ground Truths', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(OUTPUT_DIR) / 'per_ground_truth_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nFigure saved to: {Path(OUTPUT_DIR) / 'per_ground_truth_comparison.png'}\")\n",
    "    \n",
    "    # Statistical analysis\n",
    "    print(\"\\nStatistical Analysis Across Ground Truths:\")\n",
    "    print(f\"  Number of ground truths: {n_gt}\")\n",
    "    \n",
    "    # ANOVA test to check if there are significant differences across ground truths\n",
    "    gt_groups = [df_success[df_success['ground_truth'] == gt]['psnr'].values \n",
    "                 for gt in gt_names]\n",
    "    f_stat, p_value = stats.f_oneway(*gt_groups)\n",
    "    print(f\"  ANOVA F-statistic: {f_stat:.3f}, p-value: {p_value:.4f}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"  → Significant differences in quality across ground truths (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"  → No significant differences in quality across ground truths (p >= 0.05)\")\n",
    "    \n",
    "    # Coefficient of variation\n",
    "    overall_mean = df_success['psnr'].mean()\n",
    "    gt_means = df_success.groupby('ground_truth')['psnr'].mean()\n",
    "    cv = (gt_means.std() / overall_mean) * 100\n",
    "    print(f\"  Coefficient of variation: {cv:.2f}%\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nOnly one ground truth volume - skipping per-GT comparison.\")\n",
    "    print(\"Add more ground truth NIfTI files to the input folder for comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79e4f15",
   "metadata": {},
   "source": [
    "## 11. Generate Final Visualization Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08f935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive dashboard\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Overall quality distribution\n",
    "ax1 = fig.add_subplot(gs[0, :2])\n",
    "df_success.boxplot(column=['psnr'], by='mb_factor', ax=ax1)\n",
    "ax1.set_title('Reconstruction Quality Distribution by MB Factor', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('MB Factor', fontsize=12)\n",
    "ax1.set_ylabel('PSNR (dB)', fontsize=12)\n",
    "plt.sca(ax1)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# 2. Transform validation summary\n",
    "ax2 = fig.add_subplot(gs[0, 2])\n",
    "if len(df_sms) > 0:\n",
    "    validation_summary = df_sms.groupby('mb_factor')['transform_valid'].mean() * 100\n",
    "    bars = ax2.bar(validation_summary.index.astype(str), validation_summary.values, color='green', alpha=0.7)\n",
    "    ax2.axhline(y=100, color='r', linestyle='--', linewidth=2, label='Target')\n",
    "    ax2.set_ylim([0, 105])\n",
    "    ax2.set_xlabel('MB Factor', fontsize=12)\n",
    "    ax2.set_ylabel('Pass Rate (%)', fontsize=12)\n",
    "    ax2.set_title('Transform Validation', fontsize=12, fontweight='bold')\n",
    "    ax2.legend()\n",
    "\n",
    "# 3. Motion level impact\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "motion_quality = df_success.groupby('motion_level')['psnr'].mean().reindex(motion_order)\n",
    "colors = ['green', 'yellow', 'orange', 'red']\n",
    "ax3.barh(motion_order, motion_quality.values, color=colors, alpha=0.7)\n",
    "ax3.set_xlabel('Mean PSNR (dB)', fontsize=12)\n",
    "ax3.set_title('Quality by Motion Level', fontsize=12, fontweight='bold')\n",
    "ax3.invert_yaxis()\n",
    "\n",
    "# 4. Stack count impact\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "stack_quality = df_success.groupby('num_stacks')['psnr'].mean()\n",
    "ax4.plot(stack_quality.index, stack_quality.values, marker='o', linewidth=2, markersize=8, color='blue')\n",
    "ax4.set_xlabel('Number of Stacks', fontsize=12)\n",
    "ax4.set_ylabel('Mean PSNR (dB)', fontsize=12)\n",
    "ax4.set_title('Quality vs Stack Count', fontsize=12, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. SMS vs Sequential comparison\n",
    "ax5 = fig.add_subplot(gs[1, 2])\n",
    "if len(df_sequential) > 0 and len(df_sms_all) > 0:\n",
    "    comparison_data = {\n",
    "        'Sequential\\n(MB=1)': [df_sequential['psnr'].mean(), df_sequential['ssim'].mean()],\n",
    "        'SMS\\n(MB>1)': [df_sms_all['psnr'].mean(), df_sms_all['ssim'].mean()]\n",
    "    }\n",
    "    x = np.arange(len(comparison_data))\n",
    "    width = 0.35\n",
    "    psnr_vals = [v[0] for v in comparison_data.values()]\n",
    "    ssim_vals = [v[1] * 20 for v in comparison_data.values()]  # Scale SSIM for visibility\n",
    "    \n",
    "    ax5.bar(x - width/2, psnr_vals, width, label='PSNR', alpha=0.8)\n",
    "    ax5.bar(x + width/2, ssim_vals, width, label='SSIM×20', alpha=0.8)\n",
    "    ax5.set_xticks(x)\n",
    "    ax5.set_xticklabels(comparison_data.keys())\n",
    "    ax5.set_ylabel('Quality Metric', fontsize=12)\n",
    "    ax5.set_title('SMS vs Sequential', fontsize=12, fontweight='bold')\n",
    "    ax5.legend()\n",
    "\n",
    "# 6. Heatmap: PSNR by motion and MB\n",
    "ax6 = fig.add_subplot(gs[2, :])\n",
    "pivot = df_success.pivot_table(values='psnr', index='motion_level', columns='mb_factor', aggfunc='mean')\n",
    "pivot = pivot.reindex(motion_order)\n",
    "im = ax6.imshow(pivot.values, cmap='RdYlGn', aspect='auto', vmin=pivot.values.min(), vmax=pivot.values.max())\n",
    "ax6.set_xticks(np.arange(len(pivot.columns)))\n",
    "ax6.set_yticks(np.arange(len(pivot.index)))\n",
    "ax6.set_xticklabels(pivot.columns)\n",
    "ax6.set_yticklabels(pivot.index)\n",
    "ax6.set_xlabel('MB Factor', fontsize=12)\n",
    "ax6.set_ylabel('Motion Level', fontsize=12)\n",
    "ax6.set_title('Mean PSNR Heatmap: Motion Level × MB Factor', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value annotations\n",
    "for i in range(len(pivot.index)):\n",
    "    for j in range(len(pivot.columns)):\n",
    "        text = ax6.text(j, i, f'{pivot.values[i, j]:.2f}',\n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.colorbar(im, ax=ax6, label='PSNR (dB)')\n",
    "\n",
    "# Overall title\n",
    "fig.suptitle('SMS-Aware SVR Comprehensive Validation Dashboard', fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "plt.savefig(Path(OUTPUT_DIR) / 'validation_dashboard.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Dashboard saved to: {Path(OUTPUT_DIR) / 'validation_dashboard.png'}\")\n",
    "print(\"\\n✓ Validation study complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
